# Implementing ASMODEE {#asmodee}

ASMODEE is a new method for detecting recent changes in temporal trends
introduced by Jombart et al. [@Jombart2021-ws] and implemented in the R package
*trendbreaker* [@R-trendbreaker] as the function `asmodee`. Rather than
attempting to estimate significant changes in growth rates or reproduction
numbers, which can usually only be done after changes have been taking place for
a week or two, ASMODEE tries to answer the question: "*Are the last few days
matching what we would expect given the previous trend in the data?*".


```{r echo = FALSE}

cap <- "Rationale of ASMODEE. This figure illustrates the key steps of ASMODEE for detecting recent changes in temporal trends."

```

```{r asmodee, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "100%"}
knitr::include_graphics('images/asmodee.png', dpi = NA)
```

To answer this question, ASMODEE implements the following approach (Figure
\@ref(fig:asmodee)):

1. Split the data in two sets: a **testing** set formed by the most 'recent'
   data (typically the last week), and a **fitting** set one used for
   charactering trends on the past few weeks (typically 6 - 10 weeks) prior to
   the testing set.
   
2. Define a range of **candidate models** to characterise temporal trends in the
   **fitting set**.

3. Extrapolate past trends to derive a **95% prediction interval** (**PI**) for the last
   week of data.
   
4. Identify data outside the PI as outliers, suggesting either a slow-down
   (below the PI), or an acceleration (above the PI). In our algorithm for
   defining ELR for countries, we use a criteria of **3 net increases** as a
   sign of acceleration; *net increases* are defined as the number of outliers
   above the PI, minus the number of outliers below the PI, in the last 7 days.

Step 2 is the crucial one to obtain good results. Defining the right set of
**candidate models** to capture past trends is non-trivial, and is also the
non-standard part of implementing ASMODEE, as model-generation is currently not
implemented in *trendbreaker*, and requires *ad-hoc* code. In this chapter, we
provide tips and explanations on how candidate models are generated, and can be
adapted to other data streams.



## A unified interface for linear models

In this section, we outline the general principle of model generation for
ASMODEE.  All models used in ASMODEE use *trending* [@R-trending], which
provides a general interface for different types of statistical models,
including:

* `lm_model`: linear regression, wrapper for `lm`
* `glm_model`: generalized linear models (GLM), wrapper for `glm`
* `glm_nb_model`: negative binomial GLM, wrapper for `MASS:glm.nb`

The advantage of this interface is consitency of behaviours for various
operations, e.g. fitting, predictions, confidence intervals and prediction
intervals.

The formula syntax of these models is the same as in regular models, so the user
should not have new difficulties specifying models with *trending*.
For more information on the package, see the dedicated 
[website](https://www.repidemicsconsortium.org/trending/).

To use `asmodee`, the user needs to provide a `list` of *trending* models. An
example of such a list is provided by `models` in the code below, which
implements different models of cases over time:

* a constant model with Gaussian error
* a linear temporal trend with Gaussian error
* a log-linear temporal trend with Poisson distribution
* a log-linear temporal trend with Negative Binomial distribution

```{r }

library(trending)

models <- list(
  cst = lm_model(cases ~ 1),
  linear = lm_model(cases ~ date),
  poisson = glm_model(cases ~ date, family = poisson),
  nb = glm_nb_model(cases ~ date)
)

```

This assumes the data we will fit these models to will have a `cases` and a
`date` column containing, respectively, the daily case incidence and the
corresponding date as a `Date` object. However, these models would capture only
simple trends (constant, linear, or exponential), and data are typically more
complicated. The following sections illustrate how more flexible models can be
added to the list of candidate models.




## Generating candidate models: general principle 

The approach to generating many candidate models used in `regional_analysis.Rmd`
is to generate `character` strings matching *trending* models definitions (see
previous section) and then using the `eval(parse(text = my_text))` trick to turn
these into actual models. The simplest approach is to:

1. generate text matching the right-hand side of the formula of the different
   models (we later refer to this as **model content**)
   
2. build `character` strings matching model calls using the terms in 1); `sprintf`
   is particularly handy for this part
   
3. transform these `character` strings to actual model calls within a `lapply`



Here is a toy example illustrating the approach:

```{r results = "markup"}

library(trending)

# step 1
mod_content <- c("1", "test", "date", "date + tests")

# step 2
models_txt <- sprintf(
  "glm_model(cases ~ %s, family = poisson)",
  mod_content)

# step 3
models <- lapply(models_txt, function(e) eval(parse(text = e)))
class(models) # this is a list
length(models) # each component is a model
lapply(models, class) # check classes of each model

```

As the main thing that changes across models is the **model content**, the main
task boils down to generating combinations of predictors to capture different
trends in the data. To this end, we will use `expand.grid`, which creates all
possible combinations of a given set of variables. For instance, to generate all
models which:

* include a `date` effect
* may include a `test` effect
* may include a `weekday` effect
* may include a previous day's incidence as predictor (`cases_lag_1`),
  i.e. autoregressive model
  
We can use:

```{r results = "markup"}

# generate all combinations
mod_content_grid <- expand.grid(c("", "tests"),
                                "date",
                                c("", "weekday"),
                                c("", "cases_lag_1"))
mod_content_grid

# concatenate the columns
mod_content <- apply(mod_content_grid, 1, paste, collapse = " + ")
mod_content

```

We see that `mod_content` contains the relevant model content, with some
issues of additional `+` signs which will need removing. This can be done using
simple regular expressions:

```{r results = "markup"}

# load packages
pacman::p_load(tidyverse)

# comine effects to generate all possible models
# note the use of 'NA' to have models with/without effects
mod_content_grid <- expand.grid(
  c(NA, "tests"),
  "date",
  c(NA, "weekday"),
  c(NA, "cases_lag_1"))

mod_content_grid

# Use unite() to combine all columns, with sep = " + " and na.rm = TRUE
mod_content <- mod_content_grid %>% 
     unite(
          col = "models",            # name of the new united column
          1:ncol(mod_content_grid),  # columns to unite
          sep = " + ",               # separator to use in united column
          remove = TRUE,             # if TRUE, removes input cols from the data frame
          na.rm = TRUE               # if TRUE, missing values are removed before uniting
     ) %>%
  pull(models) # extract column into a character vector

# Check results
mod_content

```

We now have clean model content which can be turned into *trending* models using
the approach illustrated before. In the following sections, we highlight tricks
for capturing specific trends in the data, but all ultimately rely on the
principle illustrated here.




## Capturing periodicity

Periodic changes are often observed due to either seasonality (over long time
scales for seasonal diseases such as influenza), but are also frequent in the
case of COVID-19 due to reporting artifacts (Figure
\@ref(fig:asmodee-periodic). For instance, some countries report less cases over
a weekend, followed by a spike on the following day (*backlog* effect).


```{r echo = FALSE}

cap <- "Example of periodicity in COVID-19 data. This figure illustrates a case of weekly periodicity in raw data (red dots and plain black line) captured by ASMODEE (grey dots and model envelope)."

```

```{r asmodee-periodic, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "60%"}
knitr::include_graphics('images/asmodee_periodic.png', dpi = NA)
```

Such trends can be captured by different predictors: 

1. a strict `weekend` effect, i.e. a categorical variable distinguishing weekends
  from weekdays
2. a `weekend` effect including a backlog effect, i.e. a categorical variable
  distinguishing weekends, Mondays, and other weekdays
3. a `weekday` effect, i.e. a categorical variable distinguishing each day in the week

At the time of writing, only 2 and 3 are used in the data pipelines. Option 2)
is implemented by the function `day_of_week()` in the *scripts/* folder, also
provided below. Option 3) is implemented in base R by `weekdays`. Both functions
generate categorical variables from a `Date` input; for instance:

```{r }

#' Convert dates to factors
#'
#' This will map a `Date' vector to weekdays, with the following
#' distinction:
#' weekden, monday, of the rest of the week
#'
#' @author Thibaut
#'
#' @param date a vector of `Date`
#' 
day_of_week <- function(date) {
  day_of_week <- weekdays(date)
  out <- vapply(
    day_of_week,
    function(x) {
      if (x %in% c("Saturday", "Sunday")) {
        "weekend"
      } else if (x == "Monday") {
        "monday"
      } else {
        "rest_of_week"
      }
    },
    character(1)
  )
  factor(out, levels = c("rest_of_week", "monday", "weekend"))
} 

# generate some dates for the example
some_dates <- as.Date("2021-02-04") + 0:9
some_dates

# build new variables using dplyr
library(magrittr)
library(dplyr)
tibble(date = some_dates) %>%
  mutate(weekend = day_of_week(date), weekday = weekdays(date))

```




## Capturing trend changes in the past

ASMODEE implicitly assumes that the **fitting** set can be used to capture a
single trend. It frequently happens, however, that this time period actually saw
a change in trend, which then cannot be captured by a simple model (e.g. Figure
\@ref(fig:asmodee-change)).


```{r echo = FALSE}

cap <- "Example of trend change in COVID-19 data. This figure illustrates a case of change in temporal trends having occured during the *fitted* time period in the raw data (red dots and plain black line) captured by ASMODEE (grey dots and model envelope)."

```

```{r asmodee-change, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "60%"}
knitr::include_graphics('images/asmodee_change.png', dpi = NA)
```


The strategy we employ to address this issue is to:

1. define a breaking point date marking the change in trend
2. building a categorical variable `period` marking dates `before` and `after`
3. using an interaction term for the effect of time (variable `date`) combined
   with `period` so that the model will fit a slope `before` and `after` the
   changing point
   
In practice, we often ignore how to define 1). This can be addressed by
generating many models, each with a different breaking point, and leaving to
ASMODEE the task to select the best fitting model.

This approach is not entirely straightforward to implement; we illustrate it
below:

```{r results = "markup"}

# generate some dates for the example
some_dates <- as.Date("2021-02-04") + 0:30
some_dates

# build a dummy dataset
library(magrittr)
library(dplyr)

x <- tibble(date = some_dates) %>%
  mutate(day = as.integer(date - min(date)))

# build all changepoint variables between 10 and 20 days
min_k <- 5
max_k <- 25
k_values <- min_k:max_k
df_changepoints <- lapply(k_values,
                       function(k)
                         x %>%
                         transmute(if_else(day <= k, "before", "after")) %>%
                         pull(1)) %>%
  data.frame() %>%
  tibble() %>%
  setNames(paste0("change_", k_values))

# add changepoint variables to main data
x <- x %>%
  bind_cols(df_changepoints)
x

```

Once these variables have been created, one can build the corresponding models
using the same approach as before:

```{r results = "markup"}

library(trending)

# step 1
mod_content <- paste("date * change", k_values, sep = "_")
mod_content

# step 2
models_txt <- sprintf("glm_model(cases ~ %s, family = poisson)", mod_content)

# step 3
models <- lapply(models_txt, function(e) eval(parse(text = e)))
class(models) # this is a list
length(models) # each component is a model
models %>%
  head(4) %>% # only check for 4 models
  lapply(get_formula) # check formulas

```

Note that of course, changes in trend may happen in conjunction with other
processes, such as periodicity (e.g. Figure
\@ref(fig:asmodee-periodic-change)). In such cases, the approach illustrated at
the beginning of this chapter can be used to generate model contents
with/without change and with/without periodic effect.


```{r echo = FALSE}

cap <- "Example of trend change with periodicity in COVID-19 data. This figure illustrates a case of change in temporal trends having occured during the *fitted* time period, combined with weekly periodicity in the raw data (red dots and plain black line) captured by ASMODEE (grey dots and model envelope)."

```

```{r asmodee-periodic-change, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "60%"}
knitr::include_graphics('images/asmodee_periodic_change.png', dpi = NA)
```




## Final considerations

The approaches illustrated in this chapter should help characterise a majority
of temporal trends in other disease surveillance data. In this last section, we
provide additional insights into implementing ASMODEE for other data:


### Use AIC

The original ASMODEE publication [@Jombart2021-ws] introduces different
approaches for selecting the best model to characterise past trends. In this, we
were suggesting that **repeated K-fold cross-validation** might lead to
selecting models with better predictive power. However, we have since realised
that while this approach indeed selects models with good average predictions, it
ignores model variability, and might retain models which completely
under-estimate the variation in the data. For instance, it may retain a Poisson
model over a Negative Binomial GLM, both with similar average predictions, but
the Poisson having a much too narrow prediction interval, resulting in most data
points being classified as outliers.

The alternative is to use **Akaike's Information Criterion** (AIC,
[@Akaike1974-gm]). This approach is much faster, and as it tries to minimize the
deviance not explained by the model, it is able to select models which better
account for the variation in the data.



### Negative Binomial: the good and the bad

In many instances, the Negative Binomial (NegBin) GLM is the most appropriate
model for case counts data, as it better accounts for the variation in the data
than the Poisson GLM. So in principle, one would like to use this model for most
data. Unfortunately, the NegBin GLM is also prone to convergence issues, in
which case it merely issues a *warning* during the fitting phase. This is
especially frequent when there are zeros in the data (e.g. backlog effect).

By default, ASMODEE will ignore these models, treating them as failure (see
argument `include_fitting_warnings` in `?asmodee`). We recommend keeping this
behaviour, and ensuring as a 'backup' plan that all models formulated as a
NegBin GLM also have at least one counterpart as another type of model, such as
a Gaussian GLM or a linear regression.



### Keep it simple

ASMODEE performs best by using many simple models as candidates, rather than a
few complex ones. Indeed, complex models are prone to over-fitting, and may have
poor predictive value, so that they will not be useful to identify outliers in
the recent days. In this infrastructure, the most complex model would be that of
an exponential growth/decline (1 parameter) with a change point (2 parameters),
and effect of testing (1 parameter), and weekly periodicity with a different
offset for each day of the week (6 parameters). As our *fitting* dataset
contains 6 weeks of data (42 data points), the most complex model still has 32
degrees of freedom, which means we are unlikely to over-fit the data.


It is also important to ensure that at least one model will work in any
case. When analysing a range of locations (e.g. countries in this
infrastructure), ASMODEE will attempt to fit all candidate models to a given
country, and retain the best fitting one, ignoring models which errored or
issued warnings. However, ASMODEE will generate an error if not a single model
could be fitted to a given country. To avoid this situation, it is best to make
sure at least one model will always work. This can be achieved by using a
simple, constant model, e.g. by including the one of the following in the
candidate models:

```{r }

library(trending)
cst_lm <- lm_model(cases ~ 1)
cst_gaussian <- glm_model(cases ~ 1, family = gaussian)

```

