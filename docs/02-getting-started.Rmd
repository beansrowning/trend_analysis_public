# Getting started {#getting-started}

In this chapter, we provide an overview of the infrastructure and of how the
data pipelines work. After outlining the main folders and files and their
respective roles, we provide installation guidelines and tips for using it
locally (i.e. on your computer).


## Overview of the infrastructure

The infrastructure implements data pipelines that download national COVID-19
data from online sources, performs some analyses, classify countries by
**epidemiological level of risk** (**ELR**) and produce synthesis reports which
can be emailed to a pre-defined list of recipients. It is summarised in figure
\@ref(fig:overview). The infrastructure itself is a
[*reportfactory*](https://www.reconverse.org/reportfactory/), which provides a
structure for storing data, auxiliary scripts, reports sources and their
outputs. Its key components include:

* a set of **Rmarkdown reports** detailed in **chapter \@ref(reports)**
* a set of **github actions** implementing automated tasks on github servers, and
  detailed in **chapter \@ref(automation)**

```{r echo = FALSE}

cap <- "Overview of the infrastructure. This diagram represents the flow of information processed by the data pipelines. Data are gathered from the net by the WHO-private package *phifunc*, and processed by a series of *Rmd* reports. Some of the information products generated, indicated by a star, are not stored on github in order to reduce the size of the repository. Upon compilation, all reports outputs are stored in an /outputs/ folder (not shown on the diagram). The automated email (last step) can only be sent by github actions, as it requires SMTP credentials only stored as github secrets."

```


```{r overview, fig.align='center', echo=FALSE, fig.cap = cap}
knitr::include_graphics('images/reports_structure.png', dpi = NA)
```


## Main folders and files

 The main components are:

* **data/**: a folder where raw and clean data are stored; the content of this
  folder is not stored on github to minimize the size of the git archive

* **report_sources/**: a folder containing the sources of the `Rmd` reports doing
  the data gathering and cleaning, and all analyses; see the [reports](#reports)
  chapter for more information

* **scripts/**: a folder containing `R` scripts used in the various reports; this
  includes small helper functions to load the latest versions of the data, help
  with bits of analysis, and code for installing packages not on CRAN, which
  cannot be handled automatically by `reportfactory::install_deps()`

* **outputs/**: a folder containing all compiled reports and associated outputs,
  in timestamped folders; this content is automatically generated when using
  `reportfactory::compile_reports()`, and is only stored locally (i.e. on your
  machine), and not on github (to keep the git archive to a minimal size)
  
* **css/**: a folder containing styling for the reports

* **asmodee_outputs/**: a folder containing outputs of the main analysis, shared on
  github; this includes images (pinplots and tadpoles), **R** objects (`rds`
  files) containing re-usable analysis results (e.g. for inclusion in websites
  or dashboards), and analysis notes (indicating excluded countries, and reasons
  for their exclusions)
  
* **docs/**: a folder containing the sources and compiled versions of this
  handbook

Other useful files and folders to know of include:

* **README.Rmd**: the source of the `README.md` file, which is displayed on the
  landing package of the [github project](https://github.com/whocov/trend_analysis_public), 
  and shows the latest tadpoles figures by WHO region and also provides links to
  the corresponding `rds` files

* **run_factory.R**: the main R script for updating data, and running analysis
  reports for every WHO regions; also used by github actions
  
* **run_synthesis.R**: an R script used in github actions to generate a synthesis
  report for all countries, including a classification into levels of risk based
  on incidence, growth and trend acceleration, and for sending an email to a list of
  recipients with these documents attached
  
* **.github/workflows/**: a (hidden) folder storing the files used to define the
  github actions; see the [automation](#automation) chapter for more information
  
* **factory_config**: a simple text file containing some information about the
  name of key directories of the factory; normally will not need editing, unless
  you rename the folder containing the factory (see \@ref(downloading))



## Installing the infrastructure

The infrastructure can be installed locally by downloading the repository from
github and installing dependencies. To run the full pipeline, the user will need
an authentication token used to install the private (i.e. not publicly
available) WHO package `phifunc`, which is used for collating data.

### Downloading the repository {#downloading}

You can download the repository from the **code** tab on the 
[github page](https://github.com/whocov/trend_analysis_public)
as illustrated in the figure \@ref(fig:download).


```{r echo = FALSE}

cap <- "Downloading or cloning the repository. The repository containing the data infrastructure can be downloaded as a zip archive or cloned using github."

```

```{r download, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "100%"}
knitr::include_graphics('images/download.png', dpi = NA)
```

We recommend using *SSH* to clone the repository. For more information on
setting up an SSH access to github, see this 
[webpage](https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh).


Once you are set up to access github using SSH, you can clone the repository
using GIT from the command line in your favourite terminal, by typing:

```{bash eval = FALSE, echo = TRUE}
git clone git@github.com:whocov/trend_analysis_public.git
```

The advantage of cloning the repository rather than merely downloading a zip
archive is that you will be able to update the infrastructure automatically
using `git pull`.


By default, your local copy of the repository will be called
*trend_analysis_public*. It is possible to change this name, but you will need
to update the name of the factory in the **factory_config** file. From now on,
we will refer to this folder as **root folder**.



### Getting the phifunc authentication token

The tool we use to collate COVID-19 data is a package called `phifunc` developed
at WHO. Because this package internally uses some non-public data API, it is
currently not shared publicly, and an **authentication token** is needed to be
able to install it in **R**. This token is a kind of *password*, stored in a
file called `phifunc_token` in the root folder.

The easiest way to add this file is ask for it from someone in the COVID-19
analytics team, and add this file to the root of the project. Make sure you do
not alter or rename it. Once `phifunc_token` is present in your infrastructure,
the scripts installing dependencies will detect it automatically when run, and
you will be able to run all analyses locally.



### Installing dependencies

To install the dependencies, open the reportfactory by double-clicking on
`open.Rproj`, or otherwise starting an R session in the **root** folder
(*trend_analysis_public* by default), and copy-paste the following commands:

```{r eval = FALSE}

# install basic packages
pkg <- c("remotes", "reportfactory")
install.packages(pkg)

# install deps for the factory
reportfactory::install_deps()
source(here::here("scripts", "remote_packages.R"))

```

Note that the last operation will require the authentication token (file
`phifunc_token`) for installing *phifunc*. We will be working separately on a
similar infrastructure using data that are directly publicly available.



## Running the infrastructure locally

The data infrastructure can run in two modes:

* **remotely**, through github actions; this happens at specific times but can also
  be triggered manually
  
* **locally**, on your computer

Here, we outline the *local* use. You will find more information about the
github actions in the [automation](#automation) chapter. 


### Updating all analyses

The simplest way to update all analyses is run the script `run_factory.R` (using
`source(run_factory.R)`, or step-by-step by opening the file in Rstudio). This
will:

* download, assemble and pre-process the most recent data
* run a separate report for each WHO region, storing timestamped output in the
  `outputs/` folder, as well as figures, notes, and *rds* files in the
  `asmodee_outputs` folder
* update the *README* file with the new analyses



### Updating the data

The report `assemble_data.Rmd` performs the data download, gathering and
preparation. To update the data, run the following command within the factory:

```{r eval = FALSE}

library(reportfactory)
compile_reports(report = "assemble")

```


### Running analyses for a specific region

The report `regional_analyses.Rmd` performs all analyses for a given WHO region,
including calculations of growth rates and trend change detection using
ASMODEE. The report automatically uses the latest version of the clean data (so
needs to be run after `assemble_data.Rmd` if the data need updating). The
parameter `who_region` determines which WHO region is analysed. Possible values
are: `AFRO`, `EMRO`, `EURO` (default), `PAHO`, `SEARO`, `WPRO`. To run the
report, type:


```{r eval = FALSE}

library(reportfactory)
reg <- "EURO" # replace as appropriate
cores <- 4
compile_reports(report = "regional_analyses",
                params = list(who_region = reg, n_cores = cores),
                subfolder = reg)

```

where:

* `reg` is the letter code for the WHO region to use (in upper case)
* `cores` is the number of cores to be used for the ASMODEE analyses, which
  support parallelisation
* `subfolder` indicates the name of the folder in `outputs` where the
  timestamped results will be stored



### Generating the synthesis report

The report `elr_synthesis` collates the latest results for all WHO regions,
classifies countries by level of risk, and produces a synthesis html report,
alongside an .xlsx file `dynamics_summary.xlsx` summarising results and a list
of excluded countries in the text file `excluded_countries.txt`.

To compile this report, use:


```{r eval = FALSE}

library(reportfactory)
compile_reports(report = "elr_synthesis")

```
